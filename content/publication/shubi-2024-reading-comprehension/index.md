---
abstract: >-
  Can human reading comprehension be assessed from eye movements in reading? In this work, we address this longstanding question using large-scale eyetracking data. We focus on a cardinal and largely unaddressed variant of this question: predicting reading comprehension of a single participant for a single question from their eye movements over a single paragraph. We tackle this task using a battery of recent models from the literature, and three new multimodal language models. We evaluate the models in two different reading regimes: ordinary reading and information seeking, and examine their generalization to new textual items, new participants, and the combination of both. The evaluations suggest that the task is highly challenging, and highlight the importance of benchmarking against a strong text-only baseline. While in some cases eye movements provide improvements over such a baseline, they tend to be small. This could be due to limitations of current modelling approaches, limitations of the data, or because eye movement behavior does not sufficiently pertain to fine-grained aspects of reading comprehension processes. Our study provides an infrastructure for making further progress on this question.
slides: ""
url_pdf: ""
publication_types:
  - "1"
authors:
  - admin
  - Yoav Meiri
  - Cfir Avraham Hadar
  - Yevgeni Berzak
author_notes: []
publication: In *EMNLP 2024*
summary: This study investigates the challenge of predicting individual reading comprehension on a single passage level from eye movements using large-scale eyetracking data.
url_dataset: ""
url_project: ""
publication_short: In *EMNLP 2024*
url_source: ""
url_video: ""
title: Fine-Grained Prediction of Reading Comprehension from Eye Movements
doi: ""
featured: true
tags: []
projects: []
image:
  caption: "Reading Times"
  focal_point: ""
  preview_only: false
date: 2024-10-03T12:01:36.277Z
url_slides: ""
publishDate: 2024-10-03T00:00:00.000Z
url_poster: ""
url_code: ""
---
